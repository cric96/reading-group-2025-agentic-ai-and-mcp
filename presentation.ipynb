{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934ea36e2bbac389",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agentic AI: The MCP Era\n",
    "## How Generative AI Agents are now able to interact with the world around them!\n",
    "\n",
    "- **Author:** Gianluca Aguzzi\n",
    "- **Event:** Reading group @ Cesena - November 2025\n",
    "- **Code repository:** [todo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbdff477bc6441e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generative AI Agents?\n",
    "> **Generative AI:** Machine learning models capable of generating new content based on training data (e.g., text, images, music).\n",
    "\n",
    "> **Agents:** Autonomous entities that can perceive their environment, make decisions, and take actions to achieve specific goals.\n",
    "\n",
    "> **Generative AI Agents:** Entities that typically use Generative AI for decision-making, problem-solving, and interaction with their environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d823f4fae577a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agentic AI?\n",
    "> The core concept of **Agentic AI** is the use of AI agents to perform automated tasks with limited human intervention.\n",
    "\n",
    "- **Not completely autonomous:** Human intervention is often still required.\n",
    "- **Main focus:** Automated Tasks.\n",
    "  - *E.g., scheduling meetings, managing emails, data analysis, content creation.*\n",
    "- **Goal:** Increase efficiency and productivity by leveraging AI capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ff29407cba09d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How we may think an AI Agent works\n",
    "- Here put a simple image of an AI agent architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117dfc75d857216",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Do They Really Work? (Most of the time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8487e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LLM/Generative AI Provider\n",
    "- The backbone of most generative AI agents.\n",
    "- They provide a **unified interface** to interact with the model.\n",
    "- **Under the hood, they handle:**\n",
    "    - Model hosting\n",
    "    - Model runtime\n",
    "    - API services\n",
    "- They often provide additional features (e.g., authentication, rate limiting, monitoring).\n",
    "- **Examples:**\n",
    "    - OpenAI API\n",
    "    - Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf8617",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Memory Management\n",
    "- Agents often need to remember past interactions or context to make informed decisions.\n",
    "- Memory management systems help store, retrieve, and manage this information effectively.\n",
    "- **Types of memory:**\n",
    "    - **Short-term memory:** Temporary storage for recent interactions (e.g., chat history).\n",
    "    - **Long-term memory:** Persistent storage for important information (e.g., vector databases, SQL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09784e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tool Integration\n",
    "- Agents need to perform actions.\n",
    "- LLMs are primarily text generators; they need a mechanism to interact with the external world.\n",
    "- **Tools** are external functionalities that agents can use to perform specific tasks.\n",
    "- **Examples of tools:**\n",
    "    - Web browsers\n",
    "    - APIs (e.g., weather API, stock market API)\n",
    "    - File systems\n",
    "- *Tools are essential for enabling \"agentic\" capabilities in AI agents.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97a261",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is a Tool?\n",
    "- A **Tool** in this context is typically defined by:\n",
    "    - A **Name**\n",
    "    - A **Description**\n",
    "    - **Arguments** (Schema) that the tool expects\n",
    "- This structure allows the agent to understand *what* the tool does and *how* to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83471b1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LLMs Without Tools\n",
    "- Let's observe how an LLM behaves **without** tools.\n",
    "- **Example:** Asking for the current time.\n",
    "- *Spoiler: It will likely hallucinate or state its training data cutoff.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381a96f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LangChain\n",
    "- A popular framework for building applications with LLMs.\n",
    "- **Provides abstractions for:**\n",
    "    - Using LLMs\n",
    "    - Prompt Engineering (templates, pre-built prompts)\n",
    "    - Managing memory\n",
    "    - Integrating tools\n",
    "    - Building agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511a3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tool Integration - Few Shot Learning\n",
    "- Since LLMs have shown incredible performance with human-aligned instructions, we can use **few-shot learning** to teach them how to use tools.\n",
    "- **The Idea:**\n",
    "    1.  Inject available tool definitions into the context.\n",
    "    2.  Provide examples of how to use them.\n",
    "    3.  Let the LLM figure out *when* and *how* to use them.\n",
    "    4.  When the LLM decides to use a tool, we parse the output, execute the tool, and provide the result back to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801eb3d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demo: The Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede45ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Demo: Parsing the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bfcc8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demo: Agents with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81240d65",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Live Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16021d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tools in LangChain\n",
    "- LangChain provides a simple way to define and use tools within agents.\n",
    "- You can create a custom tool by tagging a function with the `@tool` decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94674d88",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Structured Tools\n",
    "- Under the hood, a function tagged with `@tool` is converted into a `StructuredTool`.\n",
    "- A `StructuredTool` requires:\n",
    "    - **Name**\n",
    "    - **Description**\n",
    "    - **`args_schema`**: A Pydantic model defining the arguments the tool expects.\n",
    "- This allows LangChain to automatically generate prompts and parse outputs when using the tool within an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df750a90",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## LangChain Agents\n",
    "- LangChain provides several pre-built agent types that can be easily instantiated and used.\n",
    "- **Under the hood, these agents handle:**\n",
    "    - Deciding when to use tools.\n",
    "    - Formatting prompts.\n",
    "    - Parsing tool outputs.\n",
    "    - *(and much more, but we will focus on these three).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a48d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Tool Dilemma\n",
    "- **Problem:** I often need to implement the same tool for multiple AI agents or frameworks.\n",
    "- **Fragmentation:**\n",
    "    - Initially, each library/framework had its own way to define tools.\n",
    "    - OpenAI introduced a standard using JSON Schema.\n",
    "    - Gemini had its own proprietary format.\n",
    "    - Anthropic had another.\n",
    "- **Result:** This fragmentation created significant challenges for developers (the \"N x M\" integration problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f577f7e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Towards Standardization\n",
    "- **The Goal:**\n",
    "    - Define a standard way to describe tools (name, description, arguments).\n",
    "    - Use **JSON Schema** for argument definition.\n",
    "    - Create a standard protocol to expose such tools to different AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a4ab1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCP: Model Context Protocol\n",
    "> An open standard to define and share **context** across different AI agents and frameworks.\n",
    "- **Why \"Context\" and not just \"Tools\"?**\n",
    "    - While tools are a major part, other resources can be shared too.\n",
    "    - **Resources:** File-like data that can be read by clients (e.g., logs, code files).\n",
    "    - **Prompts:** Pre-defined templates for interacting with the server.\n",
    "    - **Tools:** Executable functions.\n",
    "    - In Agentic AI literature, these are collectively referred to as \"context\".\n",
    "- MCP aims to standardize the definition and sharing of this context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e7a56d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Standardize?\n",
    "- Just as **REST APIs** standardized web services...\n",
    "- Just as **LSP (Language Server Protocol)** standardized how IDEs talk to language tools...\n",
    "- **MCP** aims to standardize how AI agents and frameworks define and share context.\n",
    "- **Origin:** Anthropic (creators of Claude) introduced the MCP standard to solve the ecosystem fragmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34646924",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MCP Components\n",
    "- **Host:** An entity that **needs** context to operate (e.g., Claude Desktop, IDEs, AI Agents).\n",
    "- **Server:** An entity that **provides** context to hosts (e.g., Google Drive MCP, Postgres MCP).\n",
    "- **Client:** An entity that interacts with the server on behalf of the host and manages the connection (1:1 connection).\n",
    "- *This architecture allows for a \"Many-to-Many\" ecosystem where any Host can talk to any Server.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529890d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overall Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c91562",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overall Interaction\n",
    "![](./images/interaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07d730",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MCP Client - Server Interaction\n",
    "- The **MCP Client** is responsible for:\n",
    "    - Connecting to the MCP Server.\n",
    "    - Requesting context (Resources, Prompts, Tools) on behalf of the Host.\n",
    "    - Handling sampling (server asking the client for completions).\n",
    "- The **MCP Server** is responsible for:\n",
    "    - Exposing context to the MCP Client.\n",
    "    - Handling requests for context.\n",
    "    - Managing tool execution requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dfe100",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Layers\n",
    "- **Data Layer (Inner):**\n",
    "  - Defines the **logic** (JSON-RPC 2.0).\n",
    "  - Handles Lifecycle, Primitives (Tools, Resources, Prompts).\n",
    "- **Transport Layer (Outer):**\n",
    "  - Defines the **communication** (Stdio, HTTP).\n",
    "  - Handles connection, message framing.\n",
    "- *Data layer is transport-agnostic.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f8c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MCP LifeCycle\n",
    "- **Stateful Protocol:** MCP requires a persistent connection state.\n",
    "- **Initialization Phase:**\n",
    "  - **Capability Negotiation:** Client and Server exchange supported features (e.g., \"I support resources\", \"I support sampling\").\n",
    "  - **Handshake:** `initialize` request $\\rightarrow$ `initialized` notification.\n",
    "- **JSON-RPC 2.0:** The standard format for all messages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764ea8e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bi-directional Communication\n",
    "- It's not just Client $\\rightarrow$ Server!\n",
    "- **Server $\\rightarrow$ Client Requests:**\n",
    "  - **Sampling:** Server asks Host to generate text (using the Host's LLM).\n",
    "  - **Create Message:** Server asks Host to show a message/input to user.\n",
    "  - **Logging:** Server sends logs to the Host console.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999dc13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Primitives & Discovery\n",
    "- **Dynamic Discovery:** Clients discover capabilities via `*/list` methods.\n",
    "  - `tools/list`, `resources/list`, `prompts/list`.\n",
    "- **Execution/Retrieval:**\n",
    "  - `tools/call`: Execute a function.\n",
    "  - `resources/read`: Get data content.\n",
    "  - `prompts/get`: Get a template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7eeec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Transport Agnosticism\n",
    "- **Decoupled Architecture:** The interaction between Client and Server is independent of the transport mechanism.\n",
    "- **Flexibility:** Clients and Servers operate identically whether over local STDIO or remote HTTP.\n",
    "- **Development Focus:** Developers can build core logic first, then plug in the appropriate transport layer (Stdio, SSE, etc.) based on deployment needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada3cbe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## STDIO Transport\n",
    "- The **STDIO Transport** uses standard input and output streams for communication.\n",
    "- **How it works:**\n",
    "    - The MCP Client and Server read from and write to their respective standard input/output streams.\n",
    "    - Messages are serialized as JSON and exchanged over these streams.\n",
    "- **Use Cases:**\n",
    "    - Local development and testing.\n",
    "    - Integrating MCP Servers as subprocesses in applications.\n",
    "    - I want to do not make my tools available over the network!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4d219",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SSE (Server-Sent Events) Transport\n",
    "- **Mechanism:** Uses HTTP for initial connection and Server-Sent Events for server-to-client messages.\n",
    "- **How it works:**\n",
    "    - **Client -> Server:** Standard HTTP POST requests (for sending commands/requests).\n",
    "    - **Server -> Client:** A persistent HTTP connection using SSE (for pushing updates/events).\n",
    "- **Pros:**\n",
    "    - **Remote Access:** Allows connecting to servers running on different machines or cloud environments.\n",
    "    - **Web Compatible:** Works well with standard web infrastructure (proxies, load balancers).\n",
    "- **Use Cases:**\n",
    "    - Cloud-hosted agents accessing local resources via a bridge.\n",
    "    - Distributed systems where agents and tools reside on different nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b576fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## OK, but how to develop an MCP Server?\n",
    "- There are multiple SDKs available to help you build MCP Servers quickly.\n",
    "- **Python SDK:** [link]\n",
    "- **Node.js SDK:** [link]\n",
    "- **Go SDK:** [link]\n",
    "- And many other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4355aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## FastMCP\n",
    "- A fast and easy-to-use MCP Server framework in Python.\n",
    "- Ok, let's make an example for time feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c85bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Debugging: The MCP Inspector\n",
    "- Developing agents is hard; debugging them is harder.\n",
    "- **MCP Inspector:** A web-based tool to test and inspect MCP Servers.\n",
    "- **Capabilities:**\n",
    "  - List available tools, resources, and prompts.\n",
    "  - Execute tools and view raw JSON-RPC messages.\n",
    "  - **Command:** `npx @modelcontextprotocol/inspector <command-to-run-server>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59978de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using MCP Servers (The Client Side)\n",
    "- **Ready-made Hosts:**\n",
    "  - **Claude Desktop:** Native support for local MCP servers.\n",
    "  - **IDEs:** VS Code (via extensions), Cursor, Zed.\n",
    "- **Programmatic Clients:**\n",
    "  - **LangChain / LangGraph:** Easily integrate MCP tools into custom agents.\n",
    "  - **Custom Scripts:** Use the SDK to build your own client.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde117d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The \"Write Once, Run Anywhere\" for AI Tools\n",
    "- **Before MCP:** Write a tool for LangChain, rewrite for Semantic Kernel, rewrite for OpenAI Assistants...\n",
    "- **With MCP:**\n",
    "  - Write the tool **once** as an MCP Server.\n",
    "  - Use it in **Claude Desktop** for manual testing/usage.\n",
    "  - Use it in **VS Code** for coding assistance.\n",
    "  - Use it in **Your Custom Agent** for automated workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb56ac9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why This Matters for Us? (Research/Dev)\n",
    "- **Scenario:** Scientific Discovery / Engineering Loop.\n",
    "  - `Code` $\\rightarrow$ `Simulation` $\\rightarrow$ `Analysis` $\\rightarrow$ `Fix`\n",
    "- **Goal:** Automate this loop with Agentic AI.\n",
    "- **MCP's Role:**\n",
    "  - Provides a standard interface to expose our simulators and analysis tools to *any* agent.\n",
    "  - Decouples the \"Tooling\" from the \"Intelligence\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebef7fd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Use Case: Alchemist Simulator\n",
    "- **Context:** A simulator for aggregate computing (Swarm Intelligence).\n",
    "- **MCP Server exposes:**\n",
    "  - `compile(yaml_spec)`: Checks if the simulation spec is valid.\n",
    "  - `simulate(yaml_spec)`: Runs the simulation and returns snapshots/metrics.\n",
    "- **The Agent:** Can iteratively write the spec, fix errors, and analyze results without human intervention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f50fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Live demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda47cf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "- **MCP is the \"REST API\" for AI Context.**\n",
    "  - Standardizes how AI models connect to data and tools.\n",
    "- **Solves Fragmentation:** No more proprietary tool definitions.\n",
    "- **Enables an Ecosystem:**\n",
    "  - **Server Devs:** Build tools once, reach all agents.\n",
    "  - **Agent Devs:** Access a massive library of existing tools.\n",
    "- **Future:** Expect MCP to become the default standard for Agentic AI integration.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "rise": {
   "center": true,
   "enable_chalkboard": false,
   "height": "100%",
   "scroll": true,
   "slideNumber": true,
   "theme": "simple",
   "transition": "slide",
   "width": "100%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
